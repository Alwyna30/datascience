{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8eb5bdb-5ef7-4b41-8778-bcc5b5fbed25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:49...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Data       Labels\n",
       "0           0  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:49...  alt.atheism\n",
       "1           1  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...  alt.atheism\n",
       "2           2  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
       "3           3  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...  alt.atheism\n",
       "4           4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...  alt.atheism"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(\"C://Users//Manisha Chandanshiv//OneDrive//ドキュメント//Excelr assignment Questions//Data Science//Naive Bayes and Text Mining//Naive Bayes and Text Mining//blogs_categories.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd67a54-31f7-44ae-9337-b57f45c68a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Manisha\n",
      "[nltk_data]     Chandanshiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Manisha\n",
      "[nltk_data]     Chandanshiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '',text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned'] = df['Data'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a8f7c2-de71-4d3c-b47b-6f960516a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X=tfidf.fit_transform(df['cleaned']).toarray()\n",
    "y= df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e1c5a3-e5c4-4df5-b22f-95110458c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "023ab22c-759f-42fb-937e-af49e9289a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred = nb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bee64a60-8da0-4ec6-8be4-064db21653c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Manisha\n",
      "[nltk_data]     Chandanshiv\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    score = sia.polarity_scores(text)\n",
    "    if score['compound'] > 0.05:\n",
    "        return 'positive'\n",
    "    elif score['compound'] < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['Sentiment'] = df['Data'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad8e2cdb-ff9d-4f12-b20f-930e869bda3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment                 negative  neutral  positive\n",
      "Labels                                               \n",
      "alt.atheism               0.379000    0.008  0.613000\n",
      "comp.graphics             0.123000    0.047  0.830000\n",
      "comp.os.ms-windows.misc   0.204000    0.045  0.751000\n",
      "comp.sys.ibm.pc.hardware  0.218000    0.019  0.763000\n",
      "comp.sys.mac.hardware     0.243000    0.047  0.710000\n",
      "comp.windows.x            0.226000    0.040  0.734000\n",
      "misc.forsale              0.126000    0.070  0.804000\n",
      "rec.autos                 0.304000    0.028  0.668000\n",
      "rec.motorcycles           0.311000    0.020  0.669000\n",
      "rec.sport.baseball        0.228000    0.039  0.733000\n",
      "rec.sport.hockey          0.259000    0.016  0.725000\n",
      "sci.crypt                 0.300000    0.007  0.693000\n",
      "sci.electronics           0.178000    0.036  0.786000\n",
      "sci.med                   0.346000    0.022  0.632000\n",
      "sci.space                 0.271000    0.021  0.708000\n",
      "soc.religion.christian    0.260782    0.000  0.739218\n",
      "talk.politics.guns        0.659000    0.010  0.331000\n",
      "talk.politics.mideast     0.649000    0.006  0.345000\n",
      "talk.politics.misc        0.526000    0.004  0.470000\n",
      "talk.religion.misc        0.389000    0.006  0.605000\n"
     ]
    }
   ],
   "source": [
    "sentiment_dist = df.groupby('Labels')['Sentiment'].value_counts(normalize=True).unstack().fillna(0)\n",
    "print(sentiment_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e1812-0fa9-4bd3-b8da-1c79375292ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
